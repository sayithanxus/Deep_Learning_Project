{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOwpC5WB5rCn"
      },
      "source": [
        "#3.YAPAY SİNİR AĞI TASARLAYARAK MODELİN PERFORMANSINI DEĞERLENDİRME VE TEST VERİSİNİN ACCURACY, PRECISION, RECALL VE F1 SKORU, KARMAŞIKLIK MATRİSİ, CLASSIFICATION REPORT'UNU GÖSTERME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0xhe5-f5wGF",
        "outputId": "104f82a9-e691-42c2-abd5-e6cb896e6681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2-CdE8HM5y88"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8vODZFr7OOx",
        "outputId": "5f5df84f-9339-4c1c-f6e4-0f2424951d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tumor', 'Normal']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir(\"/gdrive/MyDrive/Kidney_Cancer/Kidney Cancer\"))\n",
        "\n",
        "DATADIR = '/gdrive/MyDrive/Kidney_Cancer/Kidney Cancer'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uMAa6yQG7ZUz"
      },
      "outputs": [],
      "source": [
        "CATEGORIES = [\"Tumor\", \"Normal\"]\n",
        "\n",
        "#Görüntü pikseli boyutlandırma\n",
        "IMG_SIZE = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6pDukTw68Xk0"
      },
      "outputs": [],
      "source": [
        "#Veri Setini İşleme ve Liste Oluşturma\n",
        "\n",
        "all_data = []\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DATADIR, category)\n",
        "    class_num = CATEGORIES.index(category)\n",
        "    for img in os.listdir(path):\n",
        "        try:\n",
        "            img_array = cv2.imread(os.path.join(path, img))\n",
        "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "            all_data.append([new_array, class_num])\n",
        "        except Exception as e:\n",
        "            pass\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRaPDUNw8kr7",
        "outputId": "ff412fa0-bf4e-47d4-a4ca-02c38544c957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toplam Görüntü Sayısı:  10000\n"
          ]
        }
      ],
      "source": [
        "print(\"Toplam Görüntü Sayısı: \", len(all_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4RTCozRk8lno"
      },
      "outputs": [],
      "source": [
        "# Veri Setini Özellik ve Etiket olarak NumPy Dizilerine Ayırma\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in all_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "x23JRC6U_csc"
      },
      "outputs": [],
      "source": [
        "# Veriyi normalize etme\n",
        "X = X / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FxaHMizv8yh4"
      },
      "outputs": [],
      "source": [
        "# Veri Setini Eğitim, Test ve Doğrulama Olarak Bölme\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state =42)\n",
        "# Eğitim verisini bölerek doğrulama seti oluşturma\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.10, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "C36YeIaFEnvJ"
      },
      "outputs": [],
      "source": [
        "#Eğitim, Test ve Doğrulama Veri Setlerini NumPy Dizilerine Dönüştürme\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "x_val = np.array(x_val)\n",
        "y_val = np.array(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6Fzo75dEp5o",
        "outputId": "9b51019b-5133-4981-a561-a9d40b2d176d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5850, 100, 100, 3)\n",
            "(3500, 100, 100, 3)\n",
            "(650, 100, 100, 3)\n",
            "(5850,)\n",
            "(3500,)\n",
            "(650,)\n"
          ]
        }
      ],
      "source": [
        "#Veri Seti Boyutlarını Kontrol Etme\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "m3DGkTHwEtsi"
      },
      "outputs": [],
      "source": [
        "# Etiketleri One-Hot Encoding Formatına Çevirme\n",
        "train_yCl = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "test_yCl = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
        "valid_yCl = tf.keras.utils.to_categorical(y_val, num_classes=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7sbpy6hw85nO"
      },
      "outputs": [],
      "source": [
        "# Yapay Sinir Ağı Modeli\n",
        "model_nn = Sequential()\n",
        "model_nn.add(Flatten(input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "model_nn.add(Dense(256, activation='relu'))\n",
        "model_nn.add(Dropout(0.4))\n",
        "model_nn.add(Dense(128, activation='relu'))\n",
        "model_nn.add(Dropout(0.4))\n",
        "model_nn.add(Dense(2, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hYWhqJrO8-lA"
      },
      "outputs": [],
      "source": [
        "# Modeli derleme\n",
        "model_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KdpyWo_pQKOw"
      },
      "outputs": [],
      "source": [
        "#Geri Çağrılar Oluşturma\n",
        "from tensorflow import keras\n",
        "\n",
        "callback_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='model.h5',\n",
        "        monitor = 'val_accuracy', save_best_only=True, verbose=3\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=3)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSVksPC8AcP1",
        "outputId": "3ea4498e-8843-415f-b09d-4914bec22e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.8174\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97231, saving model to model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r92/92 [==============================] - 22s 223ms/step - loss: 0.5015 - accuracy: 0.8174 - val_loss: 0.1016 - val_accuracy: 0.9723\n",
            "Epoch 2/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9653\n",
            "Epoch 2: val_accuracy improved from 0.97231 to 0.98615, saving model to model.h5\n",
            "92/92 [==============================] - 15s 159ms/step - loss: 0.1096 - accuracy: 0.9653 - val_loss: 0.0391 - val_accuracy: 0.9862\n",
            "Epoch 3/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9648\n",
            "Epoch 3: val_accuracy improved from 0.98615 to 0.98769, saving model to model.h5\n",
            "92/92 [==============================] - 14s 157ms/step - loss: 0.0975 - accuracy: 0.9648 - val_loss: 0.0392 - val_accuracy: 0.9877\n",
            "Epoch 4/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9716\n",
            "Epoch 4: val_accuracy did not improve from 0.98769\n",
            "92/92 [==============================] - 12s 131ms/step - loss: 0.0812 - accuracy: 0.9716 - val_loss: 0.0379 - val_accuracy: 0.9846\n",
            "Epoch 5/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9776\n",
            "Epoch 5: val_accuracy improved from 0.98769 to 0.99231, saving model to model.h5\n",
            "92/92 [==============================] - 14s 154ms/step - loss: 0.0551 - accuracy: 0.9776 - val_loss: 0.0172 - val_accuracy: 0.9923\n",
            "Epoch 6/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9851\n",
            "Epoch 6: val_accuracy did not improve from 0.99231\n",
            "92/92 [==============================] - 15s 166ms/step - loss: 0.0385 - accuracy: 0.9851 - val_loss: 0.0243 - val_accuracy: 0.9908\n",
            "Epoch 7/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9846\n",
            "Epoch 7: val_accuracy improved from 0.99231 to 0.99385, saving model to model.h5\n",
            "92/92 [==============================] - 15s 160ms/step - loss: 0.0382 - accuracy: 0.9846 - val_loss: 0.0133 - val_accuracy: 0.9938\n",
            "Epoch 8/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9810\n",
            "Epoch 8: val_accuracy did not improve from 0.99385\n",
            "92/92 [==============================] - 15s 158ms/step - loss: 0.0434 - accuracy: 0.9810 - val_loss: 0.0706 - val_accuracy: 0.9815\n",
            "Epoch 9/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9745\n",
            "Epoch 9: val_accuracy did not improve from 0.99385\n",
            "92/92 [==============================] - 14s 153ms/step - loss: 0.0554 - accuracy: 0.9745 - val_loss: 0.0609 - val_accuracy: 0.9738\n",
            "Epoch 10/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9648\n",
            "Epoch 10: val_accuracy improved from 0.99385 to 0.99692, saving model to model.h5\n",
            "92/92 [==============================] - 13s 139ms/step - loss: 0.0857 - accuracy: 0.9648 - val_loss: 0.0164 - val_accuracy: 0.9969\n",
            "Epoch 11/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9815\n",
            "Epoch 11: val_accuracy did not improve from 0.99692\n",
            "92/92 [==============================] - 12s 131ms/step - loss: 0.0588 - accuracy: 0.9815 - val_loss: 0.0073 - val_accuracy: 0.9969\n",
            "Epoch 12/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9790\n",
            "Epoch 12: val_accuracy did not improve from 0.99692\n",
            "92/92 [==============================] - 15s 160ms/step - loss: 0.0531 - accuracy: 0.9790 - val_loss: 0.0389 - val_accuracy: 0.9862\n",
            "Epoch 13/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9791\n",
            "Epoch 13: val_accuracy did not improve from 0.99692\n",
            "92/92 [==============================] - 14s 156ms/step - loss: 0.0494 - accuracy: 0.9791 - val_loss: 0.0249 - val_accuracy: 0.9938\n",
            "Epoch 14/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9790\n",
            "Epoch 14: val_accuracy did not improve from 0.99692\n",
            "92/92 [==============================] - 14s 156ms/step - loss: 0.0432 - accuracy: 0.9790 - val_loss: 0.0182 - val_accuracy: 0.9938\n",
            "Epoch 15/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9762\n",
            "Epoch 15: val_accuracy did not improve from 0.99692\n",
            "92/92 [==============================] - 14s 156ms/step - loss: 0.0576 - accuracy: 0.9762 - val_loss: 0.0256 - val_accuracy: 0.9877\n",
            "Epoch 16/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9826\n",
            "Epoch 16: val_accuracy did not improve from 0.99692\n",
            "92/92 [==============================] - 13s 143ms/step - loss: 0.0386 - accuracy: 0.9826 - val_loss: 0.0344 - val_accuracy: 0.9877\n",
            "Epoch 17/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9745\n",
            "Epoch 17: val_accuracy did not improve from 0.99692\n",
            "92/92 [==============================] - 14s 146ms/step - loss: 0.0501 - accuracy: 0.9745 - val_loss: 0.0166 - val_accuracy: 0.9923\n",
            "Epoch 18/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9846\n",
            "Epoch 18: val_accuracy did not improve from 0.99692\n",
            "92/92 [==============================] - 14s 150ms/step - loss: 0.0370 - accuracy: 0.9846 - val_loss: 0.0132 - val_accuracy: 0.9938\n",
            "Epoch 19/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9860\n",
            "Epoch 19: val_accuracy did not improve from 0.99692\n",
            "92/92 [==============================] - 14s 155ms/step - loss: 0.0335 - accuracy: 0.9860 - val_loss: 0.0130 - val_accuracy: 0.9954\n",
            "Epoch 20/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9862\n",
            "Epoch 20: val_accuracy did not improve from 0.99692\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.0343 - accuracy: 0.9862 - val_loss: 0.0375 - val_accuracy: 0.9877\n",
            "Epoch 21/30\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9855\n",
            "Epoch 21: val_accuracy did not improve from 0.99692\n",
            "92/92 [==============================] - 14s 155ms/step - loss: 0.0348 - accuracy: 0.9855 - val_loss: 0.0221 - val_accuracy: 0.9923\n",
            "Epoch 21: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Modeli eğitme\n",
        "history = model_nn.fit(x_train, train_yCl,\n",
        "                    batch_size=64,\n",
        "                    validation_data = (x_val, valid_yCl),\n",
        "                    callbacks = callback_list,\n",
        "                    epochs = 30\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrv-YumnAgd4",
        "outputId": "5741c79c-bf7d-4800-81f1-388c90df7d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 17ms/step - loss: 0.0221 - accuracy: 0.9923\n",
            "Validation Accuracy (Neural Network): 99.23%\n",
            "110/110 [==============================] - 2s 18ms/step - loss: 0.0249 - accuracy: 0.9911\n",
            "Test Accuracy (Neural Network): 99.11%\n",
            "183/183 [==============================] - 6s 32ms/step - loss: 0.0049 - accuracy: 0.9983\n",
            "Train Accuracy (Neural Network): 1.00%\n"
          ]
        }
      ],
      "source": [
        "# Modelin performansını değerlendirme\n",
        "score_nn_val_transfer = model_nn.evaluate(x_val, valid_yCl)\n",
        "print(\"Validation Accuracy (Neural Network): {:.2f}%\".format(score_nn_val_transfer[1] * 100))\n",
        "\n",
        "score_nn_test_transfer = model_nn.evaluate(x_test, test_yCl)\n",
        "print(\"Test Accuracy (Neural Network): {:.2f}%\".format(score_nn_test_transfer[1] * 100))\n",
        "\n",
        "score_nn_train_transfer = model_nn.evaluate(x_train, train_yCl)\n",
        "print(\"Train Accuracy (Neural Network): {:.2f}%\".format(score_nn_train_transfer[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-HJsstbIaRM",
        "outputId": "fdc56112-d365-410b-da2d-9af35245ce07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 3s 22ms/step\n"
          ]
        }
      ],
      "source": [
        "# Tahmin yapma\n",
        "y_pred_nn = model_nn.predict(x_test)\n",
        "y_pred_classes_nn = np.argmax(y_pred_nn, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCXgA3p3Aj7K",
        "outputId": "5f992d6e-8bd4-4812-941f-884bd0263a89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network Test Accuracy: 0.99\n",
            "Neural Network Test Precision: 0.99\n",
            "Neural Network Test Recall: 0.99\n",
            "Neural Network Test F1 Score: 0.99\n",
            "Neural Network Confusion Matrix:\n",
            " [[1765   21]\n",
            " [  10 1704]]\n",
            "Neural Network Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      1786\n",
            "           1       0.99      0.99      0.99      1714\n",
            "\n",
            "    accuracy                           0.99      3500\n",
            "   macro avg       0.99      0.99      0.99      3500\n",
            "weighted avg       0.99      0.99      0.99      3500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Accuracy, Precision, Recall, F1 Score\n",
        "accuracy_nn = accuracy_score(y_test, y_pred_classes_nn)\n",
        "precision_nn = precision_score(y_test, y_pred_classes_nn)\n",
        "recall_nn = recall_score(y_test, y_pred_classes_nn)\n",
        "f1_nn = f1_score(y_test, y_pred_classes_nn)\n",
        "\n",
        "print(\"Neural Network Test Accuracy: {:.2f}\".format(accuracy_nn))\n",
        "print(\"Neural Network Test Precision: {:.2f}\".format(precision_nn))\n",
        "print(\"Neural Network Test Recall: {:.2f}\".format(recall_nn))\n",
        "print(\"Neural Network Test F1 Score: {:.2f}\".format(f1_nn))\n",
        "\n",
        "# Karmaşıklık Matrisi\n",
        "conf_matrix_nn = confusion_matrix(y_test, y_pred_classes_nn)\n",
        "print(\"Neural Network Confusion Matrix:\\n\", conf_matrix_nn)\n",
        "\n",
        "# Classification Report\n",
        "class_report_nn = classification_report(y_test, y_pred_classes_nn)\n",
        "print(\"Neural Network Classification Report:\\n\", class_report_nn)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}